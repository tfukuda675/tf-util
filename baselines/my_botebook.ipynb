{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# kaggleとcolaboでの利用について\n",
        "\n",
        "https://zenn.dev/currypurin/scraps/e01410c6529e8e0d3af9"
      ],
      "metadata": {
        "id": "1UYKZg2LbXhj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup colab/kaggle Notebook Enviromnemt"
      ],
      "metadata": {
        "id": "XoCI6RnLdVqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confirm platform"
      ],
      "metadata": {
        "id": "4Dsc1nDvYVji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def confirm_platform():\n",
        "    import sys\n",
        "    import os\n",
        "\n",
        "    if 'google.colab' in sys.modules:\n",
        "        return 'colab'\n",
        "    elif 'KAGGLE_URL_BASE' in set(os.environ.keys()):\n",
        "        return 'kaggle'\n",
        "\n",
        "platform = confirm_platform()\n",
        "print(f\"**Info :: Platform is {platform}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAlwLPr_YZ8_",
        "outputId": "b889617f-dd10-41b2-88e1-de2539ca85e5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Info :: Platform is colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7glnp8nkRYa",
        "outputId": "3f237b54-ebe1-4d51-fc0a-550a9d9672f2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utility for setup env"
      ],
      "metadata": {
        "id": "24zmCScJdlnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_drive_service():\n",
        "    from google.colab import auth\n",
        "    from googleapiclient.discovery import build\n",
        "    auth.authenticate_user()\n",
        "    drive_service = build(\"drive\", \"v3\")\n",
        "\n",
        "    return drive_service\n",
        "\n",
        "\n",
        "def setup_kaggle_env_on_colab(drive_service=None):\n",
        "    import io\n",
        "    from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "    results = (\n",
        "        drive_service.files()\n",
        "        .list(q=\"name = 'kaggle.json'\", fields=\"files(id)\")\n",
        "        .execute()\n",
        "    )\n",
        "    kaggle_api_key = results.get(\"files\", [])\n",
        "\n",
        "    filename = \"/root/.kaggle/kaggle.json\"\n",
        "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "    request = drive_service.files().get_media(fileId=kaggle_api_key[0][\"id\"])\n",
        "    fh = io.FileIO(filename, \"wb\")\n",
        "    downloader = MediaIoBaseDownload(fh, request)\n",
        "    done = False\n",
        "    while done is False:\n",
        "        status, done = downloader.next_chunk()\n",
        "        print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "    os.chmod(filename, 600)\n",
        "\n",
        "\n",
        "def setup_github_env_on_colab():\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"./drive\")\n",
        "\n",
        "    !mkdir /root/.ssh\n",
        "    !chmod 600 /root/.ssh\n",
        "    !cp drive/MyDrive/.ssh/id_rsa_github /root/.ssh/id_rsa\n",
        "    !cp drive/MyDrive/.ssh/id_rsa_github.pub /root/.ssh/id_rsa.pub\n",
        "    !ssh-keyscan -t rsa github.com >> /root/.ssh/known_hosts\n",
        "    !chmod 600 /root/.ssh/id_rsa\n",
        "\n",
        "    if not os.path.isdir(\"./baseline_my_utility\"):\n",
        "        !git clone git@github.com:tfukuda675/baseline_my_utility.git\n",
        "    else:\n",
        "        !cd ./baseline_my_utility;git pull;cd ../\n",
        "\n",
        "    if not os.path.isdir(\"./baseline_my_ml_models\"):\n",
        "        !git clone git@github.com:tfukuda675/baseline_my_ml_models.git\n",
        "    else:\n",
        "        !cd ./baseline_my_ml_models;git pull;cd ../\n",
        "\n"
      ],
      "metadata": {
        "id": "4ao4bUNZsy97"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### run setup env"
      ],
      "metadata": {
        "id": "5VYaer_ofdS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "if platform == \"colab\":\n",
        "    drive_service = setup_drive_service()\n",
        "    setup_kaggle_env_on_colab(drive_service=drive_service)\n",
        "    setup_github_env_on_colab()\n",
        "    sys.path.append('./baseline_my_utility')\n",
        "    sys.path.append('./baseline_my_ml_models')  \n",
        "\n",
        "elif platform == \"kaggle\":\n",
        "    sys.path.append('../usr/lib/baseline_my_utility')\n",
        "    sys.path.append('../usr/lib/baseline_my_ml_models')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9caVcPeev4F",
        "outputId": "79cd64fc-b25f-4fcc-ec5a-41ba2a3b9e5f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download 100%.\n",
            "Drive already mounted at ./drive; to attempt to forcibly remount, call drive.mount(\"./drive\", force_remount=True).\n",
            "mkdir: cannot create directory ‘/root/.ssh’: File exists\n",
            "# github.com:22 SSH-2.0-babeld-01bfc857\n",
            "Already up to date.\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX62MLOhYTYm"
      },
      "source": [
        "# Setup Python Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install library"
      ],
      "metadata": {
        "id": "Ox7WsJnggUPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ginza > /dev/null 2>&1\n",
        "!pip install -U ginza ja-ginza  > /dev/null 2>&1\n",
        "!python -m spacy download ja_core_news_sm > /dev/null 2>&1\n",
        "!pip install emoji > /dev/null 2>&1\n",
        "!pip install transformers[ja] > /dev/null 2>&1\n",
        "import pkg_resources, imp\n",
        "imp.reload(pkg_resources)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzjQAMBFgORy",
        "outputId": "df037ff0-e4f3-4d34-c962-05fab9e0a16b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'pkg_resources' from '/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import library"
      ],
      "metadata": {
        "id": "SMH5dXh4gab2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3r8wg8jYTYs",
        "outputId": "ff076040-286e-4703-d701-e4db34b994e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Info :: CUDA available. Use AMP function.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import make_column_transformer\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "#      ____________________\n",
        "#____/    NLP                   \\___________________\n",
        "#\n",
        "import emoji\n",
        "import ginza\n",
        "import spacy\n",
        "import gensim\n",
        "import transformers\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "#      ____________________\n",
        "#____/    My Libs               \\___________________\n",
        "#\n",
        "\n",
        "import importlib\n",
        "import baseline_my_utility\n",
        "import baseline_my_ml_models\n",
        "\n",
        "importlib.reload(baseline_my_utility)\n",
        "importlib.reload(baseline_my_ml_models)\n",
        "from baseline_my_utility import reduce_mem_usage\n",
        "from baseline_my_utility import tweet_clean_text, tweet_prepare_emoji, tweet_prepare_pair, tweet_transformer_data, plot_acc, plot_err\n",
        "from baseline_my_utility import bert_train\n",
        "from baseline_my_utility import bert_valid\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup input data from kaggle and GCS"
      ],
      "metadata": {
        "id": "sY6a4_DLM8mm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### google cloud strage"
      ],
      "metadata": {
        "id": "5T_2WkUWNW8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "cPMAnt96M4wA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = 'kaggle-circle'\n",
        "#!gsutil config set project {project_id}   # or !gsutil config"
      ],
      "metadata": {
        "id": "WBJiBbEDNIDb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir tweet_db_daily\n",
        "!mkdir satelite_image\n",
        "!gsutil -m cp -r gs://kxtweetana_disk/tweet_db_daily/2022-02/*.sqlite3 ./tweet_db_daily\n",
        "!gsutil -m cp -r gs://kxtweetana_disk/satelite_image/skysat/*.tif ./satelite_image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or7XG4-2NPBf",
        "outputId": "fa3c4d4c-b7c3-4a0f-d042-e4dcb60f86ff"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘tweet_db_daily’: File exists\n",
            "mkdir: cannot create directory ‘satelite_image’: File exists\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-02.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-01.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-05.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-04.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-07.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-10.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-03.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-09.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-06.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-08.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-11.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-12.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-13.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-14.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-15.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-16.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-17.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-18.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-19.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-20.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-21.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-22.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-23.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-24.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-25.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-26.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-27.sqlite3...\n",
            "Copying gs://kxtweetana_disk/tweet_db_daily/2022-02/tweets_db_2022-02-28.sqlite3...\n",
            "- [28/28 files][ 11.6 GiB/ 11.6 GiB] 100% Done  74.2 MiB/s ETA 00:00:00         \n",
            "Operation completed over 28 objects/11.6 GiB.                                    \n",
            "Copying gs://kxtweetana_disk/satelite_image/skysat/s01_20161026T091211Z.tif...\n",
            "Copying gs://kxtweetana_disk/satelite_image/skysat/s01_20141002T181504Z.tif...\n",
            "Copying gs://kxtweetana_disk/satelite_image/skysat/s03_20160822T235222Z.tif...\n",
            "Copying gs://kxtweetana_disk/satelite_image/skysat/s01_20141002T163637Z.tif...\n",
            "Copying gs://kxtweetana_disk/satelite_image/skysat/s01_20140703T190240Z.tif...\n",
            "Copying gs://kxtweetana_disk/satelite_image/skysat/s01_20141003T053408Z.tif...\n",
            "Copying gs://kxtweetana_disk/satelite_image/skysat/s01_20141003T181939Z.tif...\n",
            "- [7/7 files][  2.4 GiB/  2.4 GiB] 100% Done 100.0 MiB/s ETA 00:00:00           \n",
            "Operation completed over 7 objects/2.4 GiB.                                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### kaggle dataset"
      ],
      "metadata": {
        "id": "5Q5mUfpPNPk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle kernels output tfukuda675/xpace-bert-binary-classification-with-pseudo-data -p ./xpace-bert-binary-classification-with-pseudo-data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZmL8UGZNSS9",
        "outputId": "04758074-a14f-4fe8-da21-9b8d08aa2f56"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output file downloaded to ./xpace-bert-binary-classification-with-pseudo-data/bert_model/cl-tohoku/bert-base-japanese-whole-word-masking/config.json\n",
            "Output file downloaded to ./xpace-bert-binary-classification-with-pseudo-data/bert_model/cl-tohoku/bert-base-japanese-whole-word-masking/pytorch_model.bin\n",
            "Output file downloaded to ./xpace-bert-binary-classification-with-pseudo-data/model_fold0.pth\n",
            "Output file downloaded to ./xpace-bert-binary-classification-with-pseudo-data/model_fold1.pth\n",
            "Output file downloaded to ./xpace-bert-binary-classification-with-pseudo-data/model_fold2.pth\n",
            "Kernel log downloaded to ./xpace-bert-binary-classification-with-pseudo-data/xpace-bert-binary-classification-with-pseudo-data.log \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3H1ELR5YTYu"
      },
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "trusted": true,
        "id": "Dy0DiKq4YTYv"
      },
      "outputs": [],
      "source": [
        "debug = True\n",
        "reduce_data = False\n",
        "reduce_data_size = int(10000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2dWWnFBYTYw"
      },
      "source": [
        "# Utility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "trusted": true,
        "id": "b1HAhwQLYTYx"
      },
      "outputs": [],
      "source": [
        "def change_data_type(df):\n",
        "    ## add your modify\n",
        "    return df\n",
        "\n",
        "\n",
        "def data_clean(df):\n",
        "    \n",
        "    ## do your work\n",
        "\n",
        "    return df\n",
        "\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    print(f\"Seed set to: {seed}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "baseline-my-notebook.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}